{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XKGaVdvIuwq"
      },
      "source": [
        "**Suupervised training** <br>\n",
        "Labels 1 and 3 of some images have been augmented, so that the dataset contains more images that have labels 1 and 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtZrR6Lpamzt"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKYTa1YNahpR"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/Wound_tissue_segmentation')\n",
        "sys.path.append('/content/drive/MyDrive/Wound_tissue_segmentation/utils')\n",
        "sys.path.append('/content/drive/MyDrive/Wound_tissue_segmentation/wound_lib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWvUuJ7xZ17E"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset as BaseDataset\n",
        "import albumentations as albu\n",
        "import cv2\n",
        "import numpy as np\n",
        "import segmentation_models_pytorch as smp\n",
        "from segmentation_models_pytorch.utils import metrics, losses, base\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from copy import deepcopy\n",
        "from datetime import datetime\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1TTozpn-D8o"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx_iN5gGarSj"
      },
      "outputs": [],
      "source": [
        "class Dataset(BaseDataset):\n",
        "    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n",
        "\n",
        "    Args:\n",
        "        images_dir (str): path to images folder\n",
        "        masks_dir (str): path to segmentation masks folder\n",
        "        augmentation (albumentations.Compose): data transfromation pipeline\n",
        "            (e.g. flip, scale, etc.)\n",
        "        preprocessing (albumentations.Compose): data preprocessing\n",
        "            (e.g. noralization, shape manipulation, etc.)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            list_IDs,\n",
        "            images_dir,\n",
        "            masks_dir,\n",
        "            augmentation=None,\n",
        "            preprocessing=None,\n",
        "            to_categorical:bool=False,\n",
        "            resize=(False, (256, 256)), # To resize, the first value has to be True\n",
        "            n_classes:int=6,\n",
        "            default_img=None,\n",
        "            default_mask=None,\n",
        "    ):\n",
        "        self.ids = list_IDs\n",
        "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
        "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
        "\n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "        self.to_categorical = to_categorical\n",
        "        self.resize = resize\n",
        "        self.n_classes = n_classes\n",
        "        self.default_img = default_img\n",
        "        self.default_mask = default_mask\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        try:\n",
        "              # read data\n",
        "              image = cv2.imread(self.images_fps[i])\n",
        "              image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "              mask = cv2.imread(self.masks_fps[i], 0)     # ----------------- pay attention ------------------ #\n",
        "        except Exception as e:\n",
        "            print(\"********** Error occured loading default image and mask. *********\")\n",
        "            image = self.default_img\n",
        "            mask = self.default_mask\n",
        "\n",
        "        if self.resize[0]:\n",
        "            image = cv2.resize(image, self.resize[1], interpolation=cv2.INTER_NEAREST)\n",
        "            mask = cv2.resize(mask, self.resize[1], interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        mask = np.expand_dims(mask, axis=-1)  # adding channel axis # ----------------- pay attention ------------------ #\n",
        "\n",
        "        # apply augmentations\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        # apply preprocessing\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        if self.to_categorical:\n",
        "            mask = torch.from_numpy(mask)\n",
        "            mask = F.one_hot(mask.long(), num_classes=self.n_classes)\n",
        "            mask = mask.type(torch.float32)\n",
        "            mask = mask.numpy()\n",
        "            mask = np.squeeze(mask)\n",
        "\n",
        "            mask = np.moveaxis(mask, -1, 0)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB8RKETkALtF"
      },
      "source": [
        "### Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-ltFwaGAK3c"
      },
      "outputs": [],
      "source": [
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "\n",
        "        albu.OneOf(\n",
        "            [\n",
        "                albu.HorizontalFlip(p=0.5),\n",
        "                albu.VerticalFlip(p=0.5),\n",
        "            ],\n",
        "            p=0.8,\n",
        "        ),\n",
        "\n",
        "        albu.OneOf(\n",
        "            [\n",
        "                albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0, p=0.1, border_mode=0), # scale only\n",
        "                albu.ShiftScaleRotate(scale_limit=0, rotate_limit=30, shift_limit=0, p=0.1, border_mode=0), # rotate only\n",
        "                albu.ShiftScaleRotate(scale_limit=0, rotate_limit=0, shift_limit=0.1, p=0.6, border_mode=0), # shift only\n",
        "                albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=30, shift_limit=0.1, p=0.2, border_mode=0), # affine transform\n",
        "            ],\n",
        "            p=0.9,\n",
        "        ),\n",
        "\n",
        "        albu.OneOf(\n",
        "            [\n",
        "                albu.Perspective(p=0.2),\n",
        "                albu.GaussNoise(p=0.2),\n",
        "                albu.Sharpen(p=0.2),\n",
        "                albu.Blur(blur_limit=3, p=0.2),\n",
        "                albu.MotionBlur(blur_limit=3, p=0.2),\n",
        "            ],\n",
        "            p=0.5,\n",
        "        ),\n",
        "\n",
        "        albu.OneOf(\n",
        "            [\n",
        "                albu.CLAHE(p=0.25),\n",
        "                albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.25),\n",
        "                albu.RandomGamma(p=0.25),\n",
        "                albu.HueSaturationValue(p=0.25),\n",
        "            ],\n",
        "            p=0.3,\n",
        "        ),\n",
        "\n",
        "    ]\n",
        "\n",
        "    return albu.Compose(train_transform, p=0.9) # 90% augmentation probability\n",
        "\n",
        "\n",
        "def get_validation_augmentation():\n",
        "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
        "    test_transform = [\n",
        "        # albu.PadIfNeeded(512, 512)\n",
        "    ]\n",
        "    return albu.Compose(test_transform)\n",
        "\n",
        "\n",
        "def to_tensor(x, **kwargs):\n",
        "    return x.transpose(2, 0, 1).astype('float32')\n",
        "\n",
        "\n",
        "def get_preprocessing(preprocessing_fn):\n",
        "    \"\"\"Construct preprocessing transform\n",
        "\n",
        "    Args:\n",
        "        preprocessing_fn (callbale): data normalization function\n",
        "            (can be specific for each pretrained neural network)\n",
        "    Return:\n",
        "        transform: albumentations.Compose\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    _transform = [\n",
        "        albu.Lambda(image=preprocessing_fn),\n",
        "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
        "    ]\n",
        "    return albu.Compose(_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9xxDHfp_yFO"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq5o1vzBYxN0"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "BASE_MODEL = 'MiT+pscse'\n",
        "ENCODER = 'mit_b3'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "BATCH_SIZE = 16\n",
        "n_classes = 4\n",
        "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "LR = 0.0001 # learning rate\n",
        "EPOCHS = 500\n",
        "WEIGHT_DECAY = 1e-5\n",
        "SAVE_WEIGHTS_ONLY = True\n",
        "RESIZE = (False, (256,256)) # if resize needed\n",
        "TO_CATEGORICAL = True\n",
        "SAVE_BEST_MODEL = True\n",
        "SAVE_LAST_MODEL = False\n",
        "\n",
        "PERIOD = 10 # periodically save checkpoints\n",
        "RAW_PREDICTION = False # if true, then stores raw predictions (i.e. before applying threshold)\n",
        "RETRAIN = False\n",
        "\n",
        "# For early stopping\n",
        "EARLY_STOP = True # True to activate early stopping\n",
        "PATIENCE = 50 # for early stopping\n",
        "\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZUDgFCkKPlW"
      },
      "source": [
        "### Helper function: save a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daug57SuKNIW"
      },
      "outputs": [],
      "source": [
        "def save(model_path, epoch, model_state_dict, optimizer_state_dict):\n",
        "\n",
        "    state = {\n",
        "        'epoch': epoch + 1,\n",
        "        'state_dict': deepcopy(model_state_dict),\n",
        "        'optimizer': deepcopy(optimizer_state_dict),\n",
        "        }\n",
        "\n",
        "    torch.save(state, model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qcadi38Ac5H"
      },
      "source": [
        "### Loss, optimizer, metrics, and callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26g3jFOZyWmg"
      },
      "outputs": [],
      "source": [
        "# Loss function\n",
        "dice_loss = losses.DiceLoss()\n",
        "focal_loss = losses.FocalLoss()\n",
        "total_loss = base.SumOfLosses(dice_loss, focal_loss)\n",
        "\n",
        "# Metrics\n",
        "metrics = [\n",
        "    metrics.IoU(threshold=0.5),\n",
        "    metrics.Fscore(threshold=0.5),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp9ohG-nyZzg"
      },
      "source": [
        "\n",
        "### Model Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nr8W1S3S7EhM"
      },
      "outputs": [],
      "source": [
        "# Create a function to read names from a text file, and add extensions\n",
        "def read_names(txt_file, ext=\".png\"):\n",
        "  with open(txt_file, \"r\") as f: names = f.readlines()\n",
        "\n",
        "  names = [name.strip(\"\\n\") for name in names] # remove newline\n",
        "\n",
        "  # Names are without extensions. So, add extensions\n",
        "  names = [name + ext for name in names]\n",
        "\n",
        "  return names"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "2RJOTrSrfvDA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwRA6u_4ZvyE"
      },
      "outputs": [],
      "source": [
        "save_dir_pred_root = '/content/drive/MyDrive/Wound_tissue_segmentation/predictions'\n",
        "os.makedirs(save_dir_pred_root, exist_ok = True)\n",
        "\n",
        "aux_params=dict(\n",
        "    classes=n_classes,\n",
        "    activation=ACTIVATION,\n",
        "    dropout=0.1, # dropout ratio, default is None\n",
        ")\n",
        "\n",
        "# create segmentation model with pretrained encoder\n",
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER,\n",
        "    encoder_weights=ENCODER_WEIGHTS,\n",
        "    # aux_params=aux_params,\n",
        "    classes=n_classes,\n",
        "    activation=ACTIVATION,\n",
        "    decoder_attention_type='pscse',\n",
        ")\n",
        "\n",
        "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
        "\n",
        "model.to(DEVICE)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam([\n",
        "    dict(params=model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY),\n",
        "])\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                              factor=0.1,\n",
        "                              mode='min',\n",
        "                              patience=10,\n",
        "                              min_lr=0.00001,\n",
        "                              verbose=True,\n",
        "                              )\n",
        "\n",
        "seed = random.randint(0, 5000)\n",
        "\n",
        "print(f'seed: {seed}')\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "x_train_dir = x_valid_dir = '/content/drive/MyDrive/Wound_tissue_segmentation/Dataset/dataset_MiT_v3+aug-added/PNGImages'\n",
        "y_train_dir = y_valid_dir = '/content/drive/MyDrive/Wound_tissue_segmentation/Dataset/dataset_MiT_v3+aug-added/SegmentationClass'\n",
        "\n",
        "x_test_dir = '/content/drive/MyDrive/Wound_tissue_segmentation/Dataset/dataset_MiT_v3+aug-added/test_images'\n",
        "y_test_dir = '/content/drive/MyDrive/Wound_tissue_segmentation/Dataset/dataset_MiT_v3+aug-added/test_labels'\n",
        "\n",
        "# Read train, test, and val names\n",
        "dir_txt = '/content/drive/MyDrive/Wound_tissue_segmentation/Dataset/dataset_MiT_v3+aug-added'\n",
        "list_IDs_train = read_names(os.path.join(dir_txt, 'labeled_train_names.txt'), ext='.png')\n",
        "list_IDs_val = read_names(os.path.join(dir_txt, 'labeled_val_names.txt'), ext='.png')\n",
        "list_IDs_test = read_names(os.path.join(dir_txt, 'test_names.txt'), ext='.png')\n",
        "\n",
        "random.seed(seed) # seed for random number generator\n",
        "random.shuffle(list_IDs_train) # shuffle train names\n",
        "\n",
        "print('No. of training images: ', len(list_IDs_train))\n",
        "print('No. of validation images: ', len(list_IDs_val))\n",
        "print('No. of test images: ', len(list_IDs_test))\n",
        "\n",
        "# Create a unique model name\n",
        "model_name = BASE_MODEL + '_padded_aug_' + ENCODER + '_sup_' + datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "print(model_name)\n",
        "\n",
        "# Default images\n",
        "DEFAULT_IMG_TRAIN = cv2.imread(os.path.join(x_train_dir, list_IDs_train[0]))[:,:,::-1]\n",
        "DEFAULT_MASK_TRAIN = cv2.imread(os.path.join(y_train_dir, list_IDs_train[0]), 0)\n",
        "DEFAULT_IMG_VAL = cv2.imread(os.path.join(x_valid_dir, list_IDs_val[0]))[:,:,::-1]\n",
        "DEFAULT_MASK_VAL = cv2.imread(os.path.join(y_valid_dir, list_IDs_val[0]), 0)\n",
        "\n",
        "# Checkpoint directory\n",
        "checkpoint_loc = '/content/drive/MyDrive/Wound_tissue_segmentation/checkpoints/' + model_name\n",
        "\n",
        "# Create checkpoint directory if does not exist\n",
        "if not os.path.exists(checkpoint_loc): os.makedirs(checkpoint_loc)\n",
        "\n",
        "# if SAVE_BEST_MODEL_ONLY: checkpoint_path = os.path.join(checkpoint_loc, 'best_model.pth')\n",
        "# else: checkpoint_path = os.path.join(checkpoint_loc, \"cp-{epoch:04d}.pth\")\n",
        "\n",
        "# Dataloader ===================================================================\n",
        "train_dataset = Dataset(\n",
        "    list_IDs_train,\n",
        "    x_train_dir,\n",
        "    y_train_dir,\n",
        "    augmentation=get_training_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    to_categorical=TO_CATEGORICAL,\n",
        "    resize=(RESIZE),\n",
        "    n_classes=n_classes,\n",
        "    default_img=DEFAULT_IMG_TRAIN,\n",
        "    default_mask=DEFAULT_MASK_TRAIN,\n",
        ")\n",
        "\n",
        "valid_dataset = Dataset(\n",
        "    list_IDs_val,\n",
        "    x_valid_dir,\n",
        "    y_valid_dir,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    resize=(RESIZE),\n",
        "    to_categorical=TO_CATEGORICAL,\n",
        "    n_classes=n_classes,\n",
        "    default_img=DEFAULT_IMG_VAL,\n",
        "    default_mask=DEFAULT_MASK_VAL,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=6)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=6)\n",
        "\n",
        "# create epoch runners =========================================================\n",
        "# it is a simple loop of iterating over dataloader`s samples\n",
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model,\n",
        "    loss=total_loss,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=total_loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Train ========================================================================\n",
        "# train model for N epochs\n",
        "best_viou = 0.0\n",
        "best_vloss = 1_000_000.\n",
        "save_model = False # Initially start with False\n",
        "cnt_patience = 0\n",
        "\n",
        "store_train_loss, store_val_loss = [], []\n",
        "store_train_iou, store_val_iou = [], []\n",
        "store_train_dice, store_val_dice = [], []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print('\\nEpoch: {}'.format(epoch))\n",
        "    train_logs = train_epoch.run(train_loader)\n",
        "    valid_logs = valid_epoch.run(valid_loader)\n",
        "\n",
        "    # Store losses and metrics\n",
        "    train_loss_key = list(train_logs.keys())[0] # first key is for loss\n",
        "    val_loss_key = list(valid_logs.keys())[0] # first key is for loss\n",
        "\n",
        "    store_train_loss.append(train_logs[train_loss_key])\n",
        "    store_val_loss.append(valid_logs[val_loss_key])\n",
        "    store_train_iou.append(train_logs[\"iou_score\"])\n",
        "    store_val_iou.append(valid_logs[\"iou_score\"])\n",
        "    store_train_dice.append(train_logs[\"fscore\"])\n",
        "    store_val_dice.append(valid_logs[\"fscore\"])\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if  best_vloss > valid_logs[val_loss_key]:\n",
        "        best_vloss = valid_logs[val_loss_key]\n",
        "        print(f'Validation loss reduced. Saving the model at epoch: {epoch:04d}')\n",
        "        cnt_patience = 0 # reset patience\n",
        "        best_model_epoch = epoch\n",
        "        save_model = True\n",
        "\n",
        "    # Compare iou score\n",
        "    elif best_viou < valid_logs['iou_score']:\n",
        "        best_viou = valid_logs['iou_score']\n",
        "        print(f'Validation IoU increased. Saving the model at epoch: {epoch:04d}.')\n",
        "        cnt_patience = 0 # reset patience\n",
        "        best_model_epoch = epoch\n",
        "        save_model = True\n",
        "\n",
        "    else: cnt_patience += 1\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler.step(valid_logs[sorted(valid_logs.keys())[0]]) # monitor validation loss\n",
        "\n",
        "    # Save the model\n",
        "    if save_model:\n",
        "        save(os.path.join(checkpoint_loc, 'best_model' + '.pth'),\n",
        "            epoch+1, model.state_dict(), optimizer.state_dict())\n",
        "        save_model = False\n",
        "\n",
        "    # Early stopping\n",
        "    if EARLY_STOP and cnt_patience >= PATIENCE:\n",
        "      print(f\"Early stopping at epoch: {epoch:04d}\")\n",
        "      break\n",
        "\n",
        "    # Periodic checkpoint save\n",
        "    if not SAVE_BEST_MODEL:\n",
        "      if (epoch+1) % PERIOD == 0:\n",
        "        save(os.path.join(checkpoint_loc, f\"cp-{epoch+1:04d}.pth\"),\n",
        "            epoch+1, model.state_dict(), optimizer.state_dict())\n",
        "        print(f'Checkpoint saved for epoch {epoch:04d}')\n",
        "\n",
        "if not EARLY_STOP and SAVE_LAST_MODEL:\n",
        "    print('Saving last model')\n",
        "    save(os.path.join(checkpoint_loc, 'last_model' + '.pth'),\n",
        "        epoch+1, model.state_dict(), optimizer.state_dict())\n",
        "\n",
        "print(best_model_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot loss curves"
      ],
      "metadata": {
        "id": "lk6wLszofmdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curves =============================================================\n",
        "fig, ax = plt.subplots(1,3, figsize=(12, 3))\n",
        "\n",
        "ax[0].plot(store_train_loss, 'r')\n",
        "ax[0].plot(store_val_loss, 'b')\n",
        "ax[0].set_title('Loss curve')\n",
        "ax[0].legend(['training', 'validation'])\n",
        "\n",
        "ax[1].plot(store_train_iou, 'r')\n",
        "ax[1].plot(store_val_iou, 'b')\n",
        "ax[1].set_title('IoU curve')\n",
        "ax[1].legend(['training', 'validation'])\n",
        "\n",
        "ax[2].plot(store_train_iou, 'r')\n",
        "ax[2].plot(store_val_iou, 'b')\n",
        "ax[2].set_title('Dice curve')\n",
        "ax[2].legend(['training', 'validation'])\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "save_fig_dir = \"/content/drive/MyDrive/Wound_tissue_segmentation/plots/\"\n",
        "if not os.path.exists(save_fig_dir): os.makedirs(save_fig_dir)\n",
        "\n",
        "fig.savefig(os.path.join(save_fig_dir, model_name + '.png'))"
      ],
      "metadata": {
        "id": "D6U9yDYcflOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "R81fmCqBfaB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================== Inference ================================\n",
        "# Load model====================================================================\n",
        "checkpoint = torch.load(os.path.join(checkpoint_loc, 'best_model.pth'))\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "# Test dataloader ==============================================================\n",
        "test_dataset = Dataset(\n",
        "    list_IDs_test,\n",
        "    x_test_dir,\n",
        "    y_test_dir,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    resize=(RESIZE),\n",
        "    to_categorical=False, # don't convert to onehot now\n",
        "    n_classes=n_classes,\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                            batch_size=1,\n",
        "                            shuffle=False,\n",
        "                            num_workers=6)\n",
        "\n",
        "# Prediction ===================================================================\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import scipy.io as sio\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "save_pred = True\n",
        "threshold = 0.5\n",
        "ep = 1e-6\n",
        "raw_pred = []\n",
        "\n",
        "HARD_LINE = True\n",
        "\n",
        "# Save directory\n",
        "save_dir_pred = '/content/drive/MyDrive/Wound_tissue_segmentation/predictions/' + model_name\n",
        "save_dir_pred_pal = '/content/drive/MyDrive/Wound_tissue_segmentation/predictions_palette/' + model_name\n",
        "save_dir_pred_pal_cat = '/content/drive/MyDrive/Wound_tissue_segmentation/predictions_palette_cat/' + model_name\n",
        "if not os.path.exists(save_dir_pred): os.makedirs(save_dir_pred)\n",
        "if not os.path.exists(save_dir_pred_pal): os.makedirs(save_dir_pred_pal)\n",
        "if not os.path.exists(save_dir_pred_pal_cat): os.makedirs(save_dir_pred_pal_cat)\n",
        "\n",
        "# Create a dictionary to store metrics\n",
        "metric = {} # Nested metric format: metric[image_name][label] = [precision, recall, dice, iou]\n",
        "\n",
        "# fig, ax = plt.subplots(5,2, figsize=(10,15))\n",
        "iter_test_dataloader = iter(test_dataloader)\n",
        "\n",
        "palette = [[0, 0, 0], [255, 0, 0], [0, 255, 0], [0, 0, 255]]\n",
        "\n",
        "stp, stn, sfp, sfn = 0, 0, 0, 0\n",
        "\n",
        "for i in range(len(list_IDs_test)):\n",
        "\n",
        "    tp, tn, fp, fn = 0, 0, 0, 0\n",
        "\n",
        "    name = os.path.splitext(list_IDs_test[i])[0] # remove extension\n",
        "\n",
        "    metric[name] = {} # Creating nested dictionary\n",
        "\n",
        "    # Image-wise mean of metrics\n",
        "    i_mp, i_mr, i_mdice, i_miou = [], [], [], []\n",
        "\n",
        "    image, gt_mask = next(iter_test_dataloader) # get image and mask as Tensors\n",
        "\n",
        "    # Note: Image shape: torch.Size([1, 3, 512, 512]) and mask shape: torch.Size([1, 1, 512, 512])\n",
        "\n",
        "    pr_mask = model.predict(image.to(DEVICE)) # Move image tensor to gpu\n",
        "\n",
        "    # Convert from onehot\n",
        "    # gt_mask = torch.argmax(gt_mask_, dim=1)\n",
        "    if TO_CATEGORICAL:\n",
        "        pr_mask = torch.argmax(pr_mask, dim=1)\n",
        "\n",
        "    # pr_mask = torch.argmax(pr_mask, dim=1)\n",
        "\n",
        "    # Move to CPU and convert to numpy\n",
        "    gt_mask = gt_mask.squeeze().cpu().numpy()\n",
        "    gt_mask = np.asarray(gt_mask, dtype=np.int64) # convert to integer\n",
        "    pred = pr_mask.squeeze().cpu().numpy()\n",
        "\n",
        "    # Save raw prediction\n",
        "    if RAW_PREDICTION: raw_pred.append(pred)\n",
        "\n",
        "    # Modify prediction based on threshold\n",
        "    # pred = (pred >= threshold) * 1\n",
        "\n",
        "    # Save prediction as png\n",
        "    if save_pred:\n",
        "        \"Uncomment for non-palette\"\n",
        "        cv2.imwrite(os.path.join(save_dir_pred, list_IDs_test[i]), np.squeeze(pred).astype(np.uint8))\n",
        "\n",
        "        \"Uncomment for palette\"\n",
        "        # Palette original\n",
        "        pal_gt_mask = np.squeeze(gt_mask).astype(np.uint8)\n",
        "        pal_gt_mask = Image.fromarray(pal_gt_mask)\n",
        "        pal_gt_mask = pal_gt_mask.convert(\"P\")\n",
        "        pal_gt_mask.putpalette(np.array(palette, dtype=np.uint8))\n",
        "\n",
        "        # Palette prediction\n",
        "        pal_pred = np.squeeze(pred).astype(np.uint8)\n",
        "        pal_pred = Image.fromarray(pal_pred)\n",
        "        pal_pred = pal_pred.convert(\"P\")\n",
        "        pal_pred.putpalette(np.array(palette, dtype=np.uint8))\n",
        "\n",
        "        pal_pred.save(os.path.join(save_dir_pred_pal, list_IDs_test[i])) # store\n",
        "\n",
        "        # Concatenate gt and pred side by side\n",
        "        concat_pals = Image.new(\"RGB\", (pal_gt_mask.width+pal_gt_mask.width, pal_gt_mask.height), \"white\")\n",
        "        concat_pals.paste(pal_gt_mask, (0, 0))\n",
        "        concat_pals.paste(pal_pred, (pal_gt_mask.width, 0))\n",
        "\n",
        "        concat_pals.save(os.path.join(save_dir_pred_pal_cat, list_IDs_test[i])) # store\n",
        "\n",
        "    # Find labels in gt and prediction\n",
        "    lbl_gt = set(np.unique(gt_mask))\n",
        "    lbl_gt.remove(0) # remove 0. It is background\n",
        "    lbl_pred = set(np.unique(pred))\n",
        "    lbl_pred.remove(0) # remove 0. It is background\n",
        "\n",
        "    # All labels\n",
        "    all_lbls = lbl_gt.union(lbl_pred)\n",
        "\n",
        "    # Find labels that are not common in both gt and prediction. For such cases. IoU = 0\n",
        "    diff1 = lbl_gt - lbl_pred\n",
        "    diff2 = lbl_pred - lbl_gt\n",
        "    diffs = diff1.union(diff2) # labels that do not exist in either gt or prediction\n",
        "\n",
        "    # Labels that are in the gt but not in prediction are fn\n",
        "    if len(diff1) > 0:\n",
        "        for d1 in diff1:\n",
        "            fn_ = len(np.argwhere(gt_mask == d1))\n",
        "            fn += fn_\n",
        "            sfn += fn\n",
        "\n",
        "    # Labels that are in the prediction but not in gt are fp\n",
        "    if len(diff2) > 0:\n",
        "        for d2 in diff2:\n",
        "            fp_ = len(np.argwhere(pred == d2))\n",
        "            fp += fp_\n",
        "            sfp += fp\n",
        "\n",
        "    # Set IoU == 0 for such labels\n",
        "    if not len(diffs) == 0:\n",
        "      for diff in diffs:\n",
        "        p, r, dice, iou = 0, 0, 0, 0\n",
        "        metric[name][str(diff)] = [p, r, dice, iou]\n",
        "        print(\"%d %s: label: %s; Precision: %3.2f; Recall: %3.2f; Dice: %3.2f; IoU: %3.2f\"%(i+1, name, diff, p, r, dice, iou))\n",
        "\n",
        "    # Find labels that are common in both gt and prediction.\n",
        "    cmns = lbl_gt.intersection(lbl_pred)\n",
        "\n",
        "    # Iterate over common labels\n",
        "    for cmn in cmns:\n",
        "        gt_idx = np.where(gt_mask == cmn)\n",
        "        pred_idx = np.where(pred == cmn)\n",
        "\n",
        "        # Convert to [(x1,y1), (x2,y2), ...]\n",
        "        gt_lidx, pred_lidx = [], [] # List index\n",
        "\n",
        "        for i in range(len(gt_idx[0])):\n",
        "            gt_lidx.append((gt_idx[0][i], gt_idx[1][i]))\n",
        "\n",
        "        for i in range(len(pred_idx[0])):\n",
        "            pred_lidx.append((pred_idx[0][i], pred_idx[1][i]))\n",
        "\n",
        "        # Calculate metrics\n",
        "        gt_tidx = tuple(gt_lidx) # convert to tuple\n",
        "        pred_tidx = tuple(pred_lidx) # convert to tuple\n",
        "        tp_cord = set(gt_tidx).intersection(pred_tidx) # set operation\n",
        "        fp_cord = set(pred_tidx).difference(gt_tidx) # set operation\n",
        "        fn_cord = set(gt_tidx).difference(pred_tidx) # set operation\n",
        "\n",
        "        tp += len(tp_cord)\n",
        "        fp += len(fp_cord)\n",
        "        fn += len(fn_cord)\n",
        "\n",
        "        stp += tp\n",
        "        sfp += fp\n",
        "        sfn += fn\n",
        "\n",
        "        p = (tp/(tp + fp + ep)) * 100\n",
        "        r = (tp/(tp + fn + ep)) * 100\n",
        "        dice = (2 * tp / (2 * tp + fp + fn + ep)) * 100\n",
        "        iou = (tp/(tp + fp + fn + ep)) * 100\n",
        "\n",
        "        print(\"%d %s: label: %s; Precision: %3.2f; Recall: %3.2f; Dice: %3.2f; IoU: %3.2f\"%(i+1, name, cmn, p, r, dice, iou))\n",
        "\n",
        "        metric[name][str(cmn)] = [p, r, dice, iou]\n",
        "\n",
        "        # Keep appending metrics for all labels for the current image\n",
        "        i_mp.append(p)\n",
        "        i_mr.append(r)\n",
        "        i_mdice.append(dice)\n",
        "        i_miou.append(iou)\n",
        "\n",
        "\n",
        "# create json object from dictionary\n",
        "import json\n",
        "json_write = json.dumps(metric)\n",
        "f = open(os.path.join(save_dir_pred, \"metric.json\"), \"w\")\n",
        "f.write(json_write)\n",
        "f.close()\n",
        "\n",
        "# Data-based evalutation\n",
        "siou = (stp/(stp + sfp + sfn + ep))*100\n",
        "sprecision = (stp/(stp + sfp + ep))*100\n",
        "srecall = (stp/(stp + sfn + ep))*100\n",
        "sdice = (2 * stp / (2 * stp + sfp + sfn))*100\n",
        "\n",
        "print('siou:', siou)\n",
        "print('sprecision:', sprecision)\n",
        "print('srecall:', srecall)\n",
        "print('sdice:', sdice)\n",
        "\n",
        "# Save data-based result in a text file\n",
        "with open(os.path.join(save_dir_pred, 'result.txt'), 'w') as f:\n",
        "    print(f'iou = {siou}', file=f)\n",
        "    print(f'precision = {sprecision}', file=f)\n",
        "    print(f'recall = {srecall}', file=f)\n",
        "    print(f'dice = {sdice}', file=f)\n",
        "    print(f'best model epoch = {best_model_epoch}', file=f)\n",
        "    print(f'model name = {model_name}', file=f)"
      ],
      "metadata": {
        "id": "mDygdp9qfXax"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}